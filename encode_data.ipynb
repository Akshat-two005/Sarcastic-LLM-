{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c6c1b03-c7ad-4c65-8f64-3ffff067c424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "280002it [00:18, 14773.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved C:\\Users\\aksha\\OneDrive\\Desktop\\llm\\data\\train.bin, 12401170 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "280002it [00:19, 14092.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved C:\\Users\\aksha\\OneDrive\\Desktop\\llm\\data\\valid.bin, 12401170 tokens\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(r\"C:\\Users\\aksha\\OneDrive\\Desktop\\llm\\tokenizer\\tokenizer.model\")\n",
    "\n",
    "def encode_file(txt_path, bin_path):\n",
    "    ids = []\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in tqdm(f):\n",
    "            ids.extend(sp.encode(line))\n",
    "\n",
    "    arr = np.array(ids, dtype=np.uint16)\n",
    "    arr.tofile(bin_path)\n",
    "    print(f\"Saved {bin_path}, {len(arr)} tokens\")\n",
    "\n",
    "encode_file(\n",
    "    r\"C:\\Users\\aksha\\OneDrive\\Desktop\\llm\\data\\mixed_train.txt\",\n",
    "    r\"C:\\Users\\aksha\\OneDrive\\Desktop\\llm\\data\\train.bin\"\n",
    ")\n",
    "\n",
    "encode_file(\n",
    "    r\"C:\\Users\\aksha\\OneDrive\\Desktop\\llm\\data\\mixed_train.txt\",\n",
    "    r\"C:\\Users\\aksha\\OneDrive\\Desktop\\llm\\data\\valid.bin\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "501d5516-569a-4fb7-8763-e4658ca8187f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12401170\n",
      "[  48  250 1288 6831 3202  238 3016  408 3285   48 2472 6875 6907  671\n",
      "  250 1288 6831 3202  233  281  399 6011  225   14  238 3016  408  119\n",
      " 1764  281 6812 7432 7470 7087 7339 7113 7021 7412 7413 7107 7138 6865\n",
      "   11 1156   19  250 1288 6831 3202   29]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tokens = np.memmap(\n",
    "    r\"C:\\Users\\aksha\\OneDrive\\Desktop\\llm\\data\\train.bin\",\n",
    "    dtype=np.uint16,\n",
    "    mode=\"r\"\n",
    ")\n",
    "\n",
    "print(len(tokens))\n",
    "print(tokens[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f4f40a-8b99-487a-b075-71c11e3ec2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
